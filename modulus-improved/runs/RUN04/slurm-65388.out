[2025-03-24 04:39:16,189][main][INFO] - [94mRank: 1, Device: cuda:1[0m
[2025-03-24 04:39:16,189][main][INFO] - [94mRank: 2, Device: cuda:2[0m
[2025-03-24 04:39:16,189][main][INFO] - [94mRank: 3, Device: cuda:3[0m
[2025-03-24 04:39:16,191][main][INFO] - [94mRank: 0, Device: cuda:0[0m
[2025-03-24 04:39:16,202][main][INFO] - [94m=====================================[0m
[2025-03-24 04:39:16,202][main][INFO] - [94mConfiguration[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.data.include_sst_channel: False[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.data.fix_sst_data: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.data.fix_data_centering: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.data.fix_temporal_info: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.data.fix_december_gap: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.model.include_static_data: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.model.include_spatial_info: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.model.include_solar_radiation: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.model.include_temporal_info: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.graph.use_multimesh: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.graph.use_four_dim_spatial_location: False[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.loss.fix_inverse_variance_data: True[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mtoggles.loss.use_original_variable_weights: False[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdataset.base_path: /iopsstor/scratch/cscs/stefschu/DSM500_FPR/data/FCN_ERA5_data_v0[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdataset.samples_per_file: 1460[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdataset.sample.height: 721[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdataset.sample.width: 1440[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdataset.sample.channels: 21[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdatapipe.prefetch_queue_depth: 1[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdatapipe.num_threads: 2[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mdatapipe.seed: 21[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mmodel.dtype: bfloat16[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mmodel.activation_fn: silu[0m
[2025-03-24 04:39:16,203][main][INFO] - [94mmodel.hidden_dim: 512[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.hidden_layers: 1[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.aggregation_op: sum[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.processor_layers: 16[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.graph.mesh_level: 6[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.ddp.broadcast_buffers: False[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.ddp.find_unused_parameters: False[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.ddp.gradient_as_bucket_view: True[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mmodel.ddp.static_graph: True[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase1.iterations: 500[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase1.lr_start: 0.01[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase1.lr_end: 1.0[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase2.iterations: 2000[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase2.lr_objective: 0.005[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase3.iterations: 3000[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase3.rollout_steps_increments: 1[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mschedule.phase3.lr: 0.4[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mtesting.frequency: 50[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mtesting.rollout_steps: 8[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mtesting.samples_per_rank: 1[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mwb.mode: online[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mwb.entity: schups[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mwb.watch_model: False[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mwb.experiment_label: RUN_03[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mcheckpoint.enabled: True[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mcheckpoint.frequency: 250[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mcheckpoint.folder: checkpoints13[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mcheckpoint.names: model[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mcache.enabled: True[0m
[2025-03-24 04:39:16,204][main][INFO] - [94mcache.verbose: True[0m
[2025-03-24 04:39:16,205][main][INFO] - [94mcache.dir: /iopsstor/scratch/cscs/stefschu/DSM500_FPR/cache[0m
[2025-03-24 04:39:16,205][main][INFO] - [94m=====================================[0m
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: schups to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/wandb/wandb/run-20250324_043916-p73jcsjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Baseline_65388_25/03/24_04:39:16_RUN_03
wandb: ⭐️ View project at https://wandb.ai/schups/DSM500_FPR
wandb: 🚀 View run at https://wandb.ai/schups/DSM500_FPR/runs/p73jcsjp
[2025-03-24 04:39:17,655][trainer][INFO] - [94mSetting seed to 21[0m
[2025-03-24 04:39:17,694][cache][INFO] - [94mLoading cache for 'meshes'.[0m
[2025-03-24 04:39:17,694][cache][INFO] - [94mChecking if 'meshes' is cached.[0m
[2025-03-24 04:39:17,695][cache][INFO] - [94m-> HIT! '/iopsstor/scratch/cscs/stefschu/DSM500_FPR/cache/icosahedron_meshes.pickled' exists.[0m
[2025-03-24 04:39:17,696][cache][INFO] - [94m-> Checking guard 'MeshesCacheGuard'.[0m
[2025-03-24 04:39:21,528][trainer][INFO] - [94mModel created. Trainable parameters count is 35'247'124[0m
[2025-03-24 04:39:26,711][trainer][INFO] - [94mNo checkpoint found at: /iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/checkpoints13/model.iter000000.pth[0m
[2025-03-24 04:39:27,244][trainer][INFO] - [92mLoaded train datapipe of size 54'018 samples[0m
[2025-03-24 04:39:29,008][trainer][INFO] - [92mLoaded test datapipe of size 2'911 samples[0m
[2025-03-24 04:39:29,012][main][INFO] - [94mInitializing dataloaders...[0m
[2025-03-24 04:39:29,012][main][INFO] - [94mTraining started...[0m
[2025-03-24 04:40:23,184][trainer][INFO] - Iteration     1 | Train loss: 0.0320 | Time taken:  7.87/46.31/54.17 sec | GPU memory: 79.2 GB | Global sample ID: 35272
[2025-03-24 04:40:23,581][trainer][INFO] - Iteration     2 | Train loss: 0.0306 | Time taken:  0.00/ 0.27/ 0.27 sec | GPU memory: 82.1 GB | Global sample ID: 14710
[2025-03-24 04:40:23,979][trainer][INFO] - Iteration     3 | Train loss: 0.0289 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 5168
[2025-03-24 04:40:24,389][trainer][INFO] - Iteration     4 | Train loss: 0.0262 | Time taken:  0.00/ 0.30/ 0.30 sec | GPU memory: 82.1 GB | Global sample ID: 28245
[2025-03-24 04:40:24,783][trainer][INFO] - Iteration     5 | Train loss: 0.0239 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 20633
[2025-03-24 04:40:25,369][trainer][INFO] - Iteration     6 | Train loss: 0.0224 | Time taken:  0.00/ 0.30/ 0.30 sec | GPU memory: 82.1 GB | Global sample ID: 35049
[2025-03-24 04:40:25,762][trainer][INFO] - Iteration     7 | Train loss: 0.0208 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 45642
[2025-03-24 04:40:26,333][trainer][INFO] - Iteration     8 | Train loss: 0.0197 | Time taken:  0.00/ 0.46/ 0.46 sec | GPU memory: 82.1 GB | Global sample ID: 12346
[2025-03-24 04:40:26,724][trainer][INFO] - Iteration     9 | Train loss: 0.0177 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 35744
[2025-03-24 04:40:27,114][trainer][INFO] - Iteration    10 | Train loss: 0.0181 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 49601
[2025-03-24 04:40:27,507][trainer][INFO] - Iteration    11 | Train loss: 0.0171 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 51302
[2025-03-24 04:40:27,897][trainer][INFO] - Iteration    12 | Train loss: 0.0166 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 27483
[2025-03-24 04:40:28,289][trainer][INFO] - Iteration    13 | Train loss: 0.0145 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 15569
[2025-03-24 04:40:28,682][trainer][INFO] - Iteration    14 | Train loss: 0.0159 | Time taken:  0.00/ 0.28/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 49881
[2025-03-24 04:40:29,077][trainer][INFO] - Iteration    15 | Train loss: 0.0117 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 37575
[2025-03-24 04:40:29,473][trainer][INFO] - Iteration    16 | Train loss: 0.0121 | Time taken:  0.00/ 0.29/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 22641
[2025-03-24 04:40:29,864][trainer][INFO] - Iteration    17 | Train loss: 0.0115 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 29693
[2025-03-24 04:40:30,254][trainer][INFO] - Iteration    18 | Train loss: 0.0106 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 551
[2025-03-24 04:40:30,649][trainer][INFO] - Iteration    19 | Train loss: 0.0107 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 31338
[2025-03-24 04:40:31,042][trainer][INFO] - Iteration    20 | Train loss: 0.0096 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 42716
[2025-03-24 04:40:31,434][trainer][INFO] - Iteration    21 | Train loss: 0.0094 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 11363
[2025-03-24 04:40:31,830][trainer][INFO] - Iteration    22 | Train loss: 0.0092 | Time taken:  0.00/ 0.28/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 1632
[2025-03-24 04:40:32,227][trainer][INFO] - Iteration    23 | Train loss: 0.0081 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 11277
[2025-03-24 04:40:32,625][trainer][INFO] - Iteration    24 | Train loss: 0.0086 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 40134
[2025-03-24 04:40:33,025][trainer][INFO] - Iteration    25 | Train loss: 0.0075 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 2968
[2025-03-24 04:40:33,415][trainer][INFO] - Iteration    26 | Train loss: 0.0069 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 43078
[2025-03-24 04:40:33,826][trainer][INFO] - Iteration    27 | Train loss: 0.0070 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 40417
[2025-03-24 04:40:34,217][trainer][INFO] - Iteration    28 | Train loss: 0.0061 | Time taken:  0.00/ 0.28/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 41197
[2025-03-24 04:40:34,611][trainer][INFO] - Iteration    29 | Train loss: 0.0062 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 28704
[2025-03-24 04:40:35,005][trainer][INFO] - Iteration    30 | Train loss: 0.0052 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 468
[2025-03-24 04:40:35,396][trainer][INFO] - Iteration    31 | Train loss: 0.0054 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 15153
[2025-03-24 04:40:35,793][trainer][INFO] - Iteration    32 | Train loss: 0.0052 | Time taken:  0.00/ 0.29/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 44124
[2025-03-24 04:40:36,188][trainer][INFO] - Iteration    33 | Train loss: 0.0046 | Time taken:  0.00/ 0.28/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 27987
[2025-03-24 04:40:36,580][trainer][INFO] - Iteration    34 | Train loss: 0.0045 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 8680
[2025-03-24 04:40:36,974][trainer][INFO] - Iteration    35 | Train loss: 0.0049 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 9359
[2025-03-24 04:40:37,368][trainer][INFO] - Iteration    36 | Train loss: 0.0045 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 25893
[2025-03-24 04:40:37,765][trainer][INFO] - Iteration    37 | Train loss: 0.0044 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 19428
[2025-03-24 04:40:38,154][trainer][INFO] - Iteration    38 | Train loss: 0.0038 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 37083
[2025-03-24 04:40:38,547][trainer][INFO] - Iteration    39 | Train loss: 0.0040 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 13697
[2025-03-24 04:40:38,940][trainer][INFO] - Iteration    40 | Train loss: 0.0040 | Time taken:  0.00/ 0.29/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 30733
[2025-03-24 04:40:39,340][trainer][INFO] - Iteration    41 | Train loss: 0.0039 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 52431
[2025-03-24 04:40:39,827][trainer][INFO] - Iteration    42 | Train loss: 0.0043 | Time taken:  0.08/ 0.28/ 0.36 sec | GPU memory: 82.1 GB | Global sample ID: 51248
[2025-03-24 04:40:40,215][trainer][INFO] - Iteration    43 | Train loss: 0.0038 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 12475
[2025-03-24 04:40:40,609][trainer][INFO] - Iteration    44 | Train loss: 0.0039 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 37844
[2025-03-24 04:40:41,003][trainer][INFO] - Iteration    45 | Train loss: 0.0038 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 9516
[2025-03-24 04:40:41,396][trainer][INFO] - Iteration    46 | Train loss: 0.0036 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 31025
[2025-03-24 04:40:41,792][trainer][INFO] - Iteration    47 | Train loss: 0.0036 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 40145
[2025-03-24 04:40:42,187][trainer][INFO] - Iteration    48 | Train loss: 0.0028 | Time taken:  0.00/ 0.28/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 16552
[2025-03-24 04:40:42,588][trainer][INFO] - Iteration    49 | Train loss: 0.0033 | Time taken:  0.00/ 0.28/ 0.28 sec | GPU memory: 82.1 GB | Global sample ID: 40710
[2025-03-24 04:40:42,978][trainer][INFO] - Iteration    50 | Train loss: 0.0033 | Time taken:  0.00/ 0.28/ 0.29 sec | GPU memory: 82.1 GB | Global sample ID: 47385
Error executing job with overrides: []
Traceback (most recent call last):
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/train_graphcast.py", line 85, in main
    test_sample = next(iterator_testing)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/datapipes/era5_hdf5.py", line 250, in __iter__
    _pipeline = dali_pth.DALIGenericIterator([self.pipe], [
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/pytorch/__init__.py", line 224, in __init__
    self._first_batch = DALIGenericIterator.__next__(self)
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/pytorch/__init__.py", line 239, in __next__
    outputs = self._get_outputs()
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/base_iterator.py", line 385, in _get_outputs
    outputs.append(p.share_outputs())
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/pipeline.py", line 1215, in share_outputs
    return self._pipe.ShareOutputs()
RuntimeError: Critical error in pipeline:
Error in MIXED operator `nvidia.dali.ops.MakeContiguous` encountered:

Can't allocate 1121976320 bytes on device 1.
Current pipeline object is no longer valid.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Error executing job with overrides: []
Error executing job with overrides: []
Error executing job with overrides: []
Traceback (most recent call last):
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/train_graphcast.py", line 92, in main
    mse, global_sample_id = trainer.test(test_sample)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/utils/trainer.py", line 228, in test
    output = self.model(model_input)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/models/graph_cast_net.py", line 218, in forward
    grid_node_feats_decoded = self.checkpoint_filter(partial(
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/models/graph_cast_net.py", line 252, in checkpoint_filter
    return partial_function()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/models/components/encoder_decoder.py", line 128, in forward
    edge_feature = self.edge_mlp(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/models/components/mlp.py", line 141, in forward
    mlp_sum = sum_efeat(
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/models/components/utils.py", line 106, in sum_efeat
    src_idx, dst_idx = graph.edges()
  File "/usr/local/lib/python3.10/dist-packages/dgl/view.py", line 179, in __call__
    return self._graph.all_edges(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/dgl/heterograph.py", line 3591, in all_edges
    src, dst, eid = self._graph.edges(self.get_etype_id(etype), order)
  File "/usr/local/lib/python3.10/dist-packages/dgl/heterograph_index.py", line 696, in edges
    edge_array = _CAPI_DGLHeteroEdges(self, int(etype), order)
  File "dgl/_ffi/_cython/./function.pxi", line 295, in dgl._ffi._cy3.core.FunctionBase.__call__
  File "dgl/_ffi/_cython/./function.pxi", line 227, in dgl._ffi._cy3.core.FuncCall
  File "dgl/_ffi/_cython/./function.pxi", line 217, in dgl._ffi._cy3.core.FuncCall3
dgl._ffi.base.DGLError: [04:40:51] /workspace/ktangsali/dgl/src/runtime/cuda/cuda_device_api.cc:117: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: out of memory
Stack trace:
  [bt] (0) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x58) [0x400179e71418]
  [bt] (1) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::AllocDataSpace(DGLContext, unsigned long, unsigned long, DGLDataType)+0x220) [0x40017a91fb64]
  [bt] (2) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0xd8) [0x40017a4feac4]
  [bt] (3) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::aten::NewIdArray(long, DGLContext, unsigned char)+0x98) [0x400179e3d8c0]
  [bt] (4) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::Range<(DGLDeviceType)2, int>(int, int, DGLContext)+0xc8) [0x40017a95ce4c]
  [bt] (5) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::aten::Range(long, long, unsigned char, DGLContext)+0x168) [0x400179e3dc58]
  [bt] (6) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::UnitGraph::COO::Edges(unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const+0x1d8) [0x40017a88c818]
  [bt] (7) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::UnitGraph::Edges(unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const+0x1c4) [0x40017a87e298]
  [bt] (8) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::HeteroGraph::Edges(unsigned long, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const+0x78) [0x40017a61221c]



Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/train_graphcast.py", line 85, in main
    test_sample = next(iterator_testing)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/datapipes/era5_hdf5.py", line 250, in __iter__
    _pipeline = dali_pth.DALIGenericIterator([self.pipe], [
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/pytorch/__init__.py", line 224, in __init__
    self._first_batch = DALIGenericIterator.__next__(self)
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/pytorch/__init__.py", line 239, in __next__
    outputs = self._get_outputs()
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/base_iterator.py", line 385, in _get_outputs
    outputs.append(p.share_outputs())
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/pipeline.py", line 1215, in share_outputs
    return self._pipe.ShareOutputs()
RuntimeError: Critical error in pipeline:
Error in MIXED operator `nvidia.dali.ops.MakeContiguous` encountered:

Can't allocate 1121976320 bytes on device 0.
Current pipeline object is no longer valid.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/train_graphcast.py", line 85, in main
    test_sample = next(iterator_testing)
  File "/iopsstor/scratch/cscs/stefschu/DSM500_FPR/modulus-baseline/modulus/datapipes/era5_hdf5.py", line 250, in __iter__
    _pipeline = dali_pth.DALIGenericIterator([self.pipe], [
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/pytorch/__init__.py", line 224, in __init__
    self._first_batch = DALIGenericIterator.__next__(self)
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/pytorch/__init__.py", line 239, in __next__
    outputs = self._get_outputs()
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/plugin/base_iterator.py", line 385, in _get_outputs
    outputs.append(p.share_outputs())
  File "/usr/local/lib/python3.10/dist-packages/nvidia/dali/pipeline.py", line 1215, in share_outputs
    return self._pipe.ShareOutputs()
RuntimeError: Critical error in pipeline:
Error in MIXED operator `nvidia.dali.ops.MakeContiguous` encountered:

Can't allocate 1121976320 bytes on device 2.
Current pipeline object is no longer valid.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mBaseline_65388_25/03/24_04:39:16_RUN_03[0m at: [34mhttps://wandb.ai/schups/DSM500_FPR/runs/p73jcsjp[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/wandb/run-20250324_043916-p73jcsjp/logs[0m
srun: error: nid006630: task 3: Exited with exit code 1
srun: Terminating StepId=65388.0
slurmstepd: error: *** STEP 65388.0 ON nid006630 CANCELLED AT 2025-03-24T04:40:54 ***
srun: error: nid006630: tasks 1-2: Exited with exit code 1
srun: error: nid006630: task 0: Terminated
srun: Force Terminated StepId=65388.0
