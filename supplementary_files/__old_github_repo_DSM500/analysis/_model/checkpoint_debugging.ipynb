{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/iopsstor/scratch/cscs/stefschu/DSM500/github/modulus-a5275d8/modulus/distributed/manager.py:346: UserWarning: Could not initialize using ENV, SLURM or OPENMPI methods. Assuming this is a single process job\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import apex.optimizers\n",
    "\n",
    "from modulus.distributed import DistributedManager\n",
    "from modulus.models_new.graphcast.graph_cast_net_newest import GraphCastNetNew\n",
    "from modulus.utils_new.caching import Cache\n",
    "from modulus.utils.graphcast.loss import GraphCastLossFunction\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR, LambdaLR\n",
    "\n",
    "\n",
    "DistributedManager.initialize()\n",
    "dist = DistributedManager()\n",
    "Cache.initialize(dir=\"/iopsstor/scratch/cscs/stefschu/DSM500/cache\")\n",
    "\n",
    "cp_path = \"/iopsstor/scratch/cscs/stefschu/DSM500/github/analysis/_model/optimizer_checkpoint_test.checkpoint\"\n",
    "\n",
    "def instantiate(dtype):\n",
    "    # Instantiate the model\n",
    "    model = GraphCastNetNew(                    # Typical values\n",
    "        sample_height=721,        # 721\n",
    "        sample_width=1440,          # 1440\n",
    "        sample_channels=21,    # 21\n",
    "        \n",
    "        include_static_data=True,         # True\n",
    "        include_spatial_info=True,         # True\n",
    "        include_temporal_info=True,         # True\n",
    "        include_solar_radiation=True,         # True\n",
    "\n",
    "        batch_size=1,      # 1\n",
    "        mesh_level=6,               # 6\n",
    "        activation_fn=\"silu\",         # \"silu\",\n",
    "        hidden_dim=128,               # 512\n",
    "        hidden_layers=1,         # 1\n",
    "        aggregation_op=\"sum\",       # \"sum\"\n",
    "        processor_layers=3,   # 16\n",
    "    )\n",
    "    model = model.to(dtype).to(dist.device)\n",
    "\n",
    "    # Define a loss function\n",
    "    criterion = GraphCastLossFunction()\n",
    "\n",
    "    # Define an optimizer\n",
    "    optimizer = apex.optimizers.FusedAdam(\n",
    "        model.parameters(),\n",
    "        lr=0.01,\n",
    "        betas=(0.9, 0.95),\n",
    "        adam_w_mode=True,\n",
    "        weight_decay=0.1,\n",
    "    )\n",
    "\n",
    "    scheduler = SequentialLR(\n",
    "        optimizer,\n",
    "        schedulers=[\n",
    "            LinearLR(\n",
    "                optimizer,\n",
    "                start_factor=1e-3,\n",
    "                end_factor=1.0,\n",
    "                total_iters=1000,\n",
    "            ),\n",
    "            CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=10000,\n",
    "                eta_min=0.0,\n",
    "            ),\n",
    "            LambdaLR(\n",
    "                optimizer,\n",
    "                lr_lambda=lambda epoch: 1e-3,\n",
    "            ),\n",
    "        ],\n",
    "        milestones=[\n",
    "            1000,\n",
    "            10000\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    input_data = torch.ones((1, 1, 31, 721, 1440)).to(dtype).to(dist.device)\n",
    "    target = torch.ones((1, 1, 21, 721, 1440)).to(dtype).cuda(dist.device)\n",
    "\n",
    "    return model, criterion, optimizer, scheduler, input_data, target, dtype\n",
    "\n",
    "def train(model, criterion, optimizer, scheduler, input_data, target, dtype):\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, criterion, optimizer, scheduler, input_data, target, dtype = instantiate(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9990000000000003e-05\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, scheduler, input_data, target, dtype)\n",
    "print(scheduler.get_last_lr()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9980000000000004e-05\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, scheduler, input_data, target, dtype)\n",
    "print(scheduler.get_last_lr()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_milestones': [1000, 10000],\n",
       " 'last_epoch': 2,\n",
       " '_last_lr': [2.9980000000000004e-05],\n",
       " '_schedulers': [{'start_factor': 0.001,\n",
       "   'end_factor': 1.0,\n",
       "   'total_iters': 1000,\n",
       "   'base_lrs': [0.01],\n",
       "   'last_epoch': 2,\n",
       "   'verbose': False,\n",
       "   '_step_count': 3,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [2.9980000000000004e-05]},\n",
       "  {'T_max': 10000,\n",
       "   'eta_min': 0.0,\n",
       "   'base_lrs': [0.01],\n",
       "   'last_epoch': -1,\n",
       "   'verbose': False,\n",
       "   '_step_count': 1,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [1e-05]},\n",
       "  {'base_lrs': [0.01],\n",
       "   'last_epoch': -1,\n",
       "   'verbose': False,\n",
       "   '_step_count': 1,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [1e-05],\n",
       "   'lr_lambdas': [None]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = torch.load(\"/iopsstor/scratch/cscs/stefschu/DSM500/github/analysis/checkpoints/model.iter001000.pth\", map_location=dist.device, weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_milestones': [1000, 310000],\n",
       " 'last_epoch': 1000,\n",
       " '_last_lr': [0.001],\n",
       " '_schedulers': [{'start_factor': 0.001,\n",
       "   'end_factor': 1.0,\n",
       "   'total_iters': 1000,\n",
       "   'base_lrs': [0.001],\n",
       "   'last_epoch': 999,\n",
       "   'verbose': False,\n",
       "   '_step_count': 1000,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.0009990009999999955]},\n",
       "  {'T_max': 299000,\n",
       "   'eta_min': 0.0,\n",
       "   'base_lrs': [0.001],\n",
       "   'last_epoch': 0,\n",
       "   'verbose': False,\n",
       "   '_step_count': 2,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.001]},\n",
       "  {'base_lrs': [0.001],\n",
       "   'last_epoch': -1,\n",
       "   'verbose': False,\n",
       "   '_step_count': 1,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.0001],\n",
       "   'lr_lambdas': [None]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp[\"scheduler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "scheduler.load_state_dict(cp[\"scheduler\"])\n",
    "print(scheduler.get_last_lr()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_milestones': [1000, 310000],\n",
       " 'last_epoch': 1000,\n",
       " '_last_lr': [0.001],\n",
       " '_schedulers': [{'start_factor': 0.001,\n",
       "   'end_factor': 1.0,\n",
       "   'total_iters': 1000,\n",
       "   'base_lrs': [0.001],\n",
       "   'last_epoch': 999,\n",
       "   'verbose': False,\n",
       "   '_step_count': 1000,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.0009990009999999955]},\n",
       "  {'T_max': 299000,\n",
       "   'eta_min': 0.0,\n",
       "   'base_lrs': [0.001],\n",
       "   'last_epoch': 0,\n",
       "   'verbose': False,\n",
       "   '_step_count': 2,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.001]},\n",
       "  {'base_lrs': [0.001],\n",
       "   'last_epoch': -1,\n",
       "   'verbose': False,\n",
       "   '_step_count': 1,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.0001],\n",
       "   'lr_lambdas': [None]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "> First training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> First training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model, criterion, optimizer \u001b[38;5;241m=\u001b[39m instantiate(torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[1;32m      5\u001b[0m train(model, criterion, optimizer)\n\u001b[1;32m      7\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(model\u001b[38;5;241m.\u001b[39mparameters())\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "print(\"-\" * 80)\n",
    "print(\"> First training\")\n",
    "model, criterion, optimizer, dtype = instantiate(torch.bfloat16)\n",
    "train(model, criterion, optimizer, dtype)\n",
    "\n",
    "p = next(model.parameters())\n",
    "print(f\"Model parameter:              [{p.min():28.25f}, {p.max():28.25f}] | {p.dtype} | {p.device} | {p.shape}\")\n",
    "p = optimizer.param_groups[0][\"params\"][0]\n",
    "print(f\"Optimizer parameter:          [{p.min():28.25f}, {p.max():28.25f}] | {p.dtype} | {p.device} | {p.shape}\")\n",
    "state = next(iter(optimizer.state.values()))\n",
    "_iter = iter(state.items())\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "\n",
    "##########################################\n",
    "print(\"-\" * 80)\n",
    "print(\"> Review state dict\")\n",
    "\n",
    "state = next(iter(optimizer.state_dict()[\"state\"].values()))\n",
    "_iter = iter(state.items())\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "\n",
    "##########################################\n",
    "print(\"-\" * 80)\n",
    "print(\"> save + load, then review state dict again\")\n",
    "\n",
    "torch.save({\"optimizer\": optimizer.state_dict()}, cp_path)\n",
    "cp = torch.load(cp_path, map_location=\"cuda:0\", weights_only=True)[\"optimizer\"]\n",
    "state = next(iter(cp[\"state\"].values()))\n",
    "_iter = iter(state.items())\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "\n",
    "##########################################\n",
    "print(\"-\" * 80)\n",
    "print(\"> Initialize model\")\n",
    "model, criterion, optimizer = instantiate()\n",
    "\n",
    "p = next(model.parameters())\n",
    "print(f\"Model parameter:              [{p.min():28.25f}, {p.max():28.25f}] | {p.dtype} | {p.device} | {p.shape}\")\n",
    "p = optimizer.param_groups[0][\"params\"][0]\n",
    "print(f\"Optimizer parameter:          [{p.min():28.25f}, {p.max():28.25f}] | {p.dtype} | {p.device} | {p.shape}\")\n",
    "\n",
    "##########################################\n",
    "print(\"-\" * 80)\n",
    "print(\"> Reload optimizer (WITHOUT FIX)\")\n",
    "\n",
    "optimizer.load_state_dict(cp)\n",
    "\n",
    "state = next(iter(optimizer.state.values()))\n",
    "_iter = iter(state.items())\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "\n",
    "\n",
    "##########################################\n",
    "print(\"-\" * 80)\n",
    "print(\"> Reload optimizer (WITH FIX)\")\n",
    "\n",
    "\n",
    "\n",
    "optimizer.load_state_dict(cp)\n",
    "\n",
    "state = next(iter(optimizer.state.values()))\n",
    "_iter = iter(state.items())\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the checkpoint:\n",
      "Optimizer state (exp_avg   ): [-0.0072753923013806343078613,  0.0070312516763806343078613] | torch.float32  | cuda:0 | torch.Size([128, 31])\n",
      "Optimizer state (exp_avg_sq): [ 0.0000000017291771348126872,  0.0002646566135808825492859] | torch.float32  | cuda:0 | torch.Size([128, 31])\n",
      "\n",
      "After loading from checkpoint:\n",
      "Optimizer state:  (exp_avg   ): [-0.0072631835937500000000000,  0.0070190429687500000000000] | torch.bfloat16  | cuda:0 | torch.Size([128, 31])\n",
      "Checkpoint state: (exp_avg   ): [-0.0072753923013806343078613,  0.0070312516763806343078613] | torch.float32  | cuda:0 | torch.Size([128, 31])\n",
      "Optimizer state:  (exp_avg_sq): [ 0.0000000017316779121756554,  0.0002651214599609375000000] | torch.bfloat16  | cuda:0 | torch.Size([128, 31])\n",
      "Checkpoint state: (exp_avg_sq): [ 0.0000000017291771348126872,  0.0002646566135808825492859] | torch.float32  | cuda:0 | torch.Size([128, 31])\n",
      "\n",
      "After fix:\n",
      "Optimizer state (exp_avg   ): [-0.0072753923013806343078613,  0.0070312516763806343078613] | torch.float32  | cuda:0 | torch.Size([128, 31])\n",
      "Optimizer state (exp_avg_sq): [ 0.0000000017291771348126872,  0.0002646566135808825492859] | torch.float32  | cuda:0 | torch.Size([128, 31])\n"
     ]
    }
   ],
   "source": [
    "_cp = torch.load(cp_path, map_location=\"cuda:0\", weights_only=True)[\"optimizer\"]\n",
    "\n",
    "print(\"In the checkpoint:\")\n",
    "for state in _cp[\"state\"].values():\n",
    "    for k, v in state.items():\n",
    "        print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "    break\n",
    "\n",
    "model, criterion, optimizer, dtype = instantiate(dtype=torch.bfloat16)\n",
    "\n",
    "print()\n",
    "print(\"After loading from checkpoint:\")\n",
    "optimizer.load_state_dict(_cp)\n",
    "\n",
    "# Convert state tensors to desired dtype\n",
    "for op_state, cp_state in zip(optimizer.state.values(), _cp[\"state\"].values()):\n",
    "    for (op_k, op_v), (cp_k, cp_v) in zip(op_state.items(), cp_state.items()):\n",
    "        print(f\"Optimizer state:  ({op_k:10}): [{op_v.min():28.25f}, {op_v.max():28.25f}] | {op_v.dtype}  | {op_v.device} | {op_v.shape}\")\n",
    "        print(f\"Checkpoint state: ({cp_k:10}): [{cp_v.min():28.25f}, {cp_v.max():28.25f}] | {cp_v.dtype}  | {cp_v.device} | {cp_v.shape}\")\n",
    "        op_state[op_k] = op_state[op_k].to(torch.float32)\n",
    "        op_state[op_k] = cp_v\n",
    "    break\n",
    "\n",
    "print()\n",
    "print(\"After fix:\")\n",
    "state = next(iter(optimizer.state.values()))\n",
    "_iter = iter(state.items())\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")\n",
    "k, v = next(_iter)\n",
    "print(f\"Optimizer state ({k:10}): [{v.min():28.25f}, {v.max():28.25f}] | {v.dtype}  | {v.device} | {v.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_arm64",
   "language": "python",
   "name": "venv_arm64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
