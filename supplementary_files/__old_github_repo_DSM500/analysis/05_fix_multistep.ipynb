{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mProvided checkpoint directory /iopsstor/scratch/cscs/stefschu/DSM500/github/analysis/checkpoints does not exist, skipping load\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded validation datapipe of size 6\n"
     ]
    }
   ],
   "source": [
    "%run __common.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nvidia/dali/pipeline.py:912: Warning: The external source node '<modulus.datapipes.climate.era5_hdf5.ERA5DaliExternalSource object at 0xfff4e1865780>' produces 4 outputs, but the outputs at the indices 2, 3 are not used. For best performance, adjust your callback so that it computes only the needed outputs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 721, 1440]) torch.bfloat16 torch.Size([1, 1, 21, 721, 1440]) torch.bfloat16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1875, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_orig = ERA5HDF5Datapipe(\n",
    "    data_dir=to_absolute_path(os.path.join(cfg.dataset_path, \"train\")),\n",
    "    stats_dir=to_absolute_path(os.path.join(cfg.dataset_path, \"stats\")),\n",
    "    channels=channels_list,\n",
    "    latlon_resolution=cfg.latlon_res,\n",
    "    interpolation_type=None,\n",
    "    num_samples_per_year=cfg.num_samples_per_year_train,\n",
    "    num_steps=1,\n",
    "    num_history=cfg.num_history,\n",
    "    use_cos_zenith=cfg.use_cos_zenith,\n",
    "    use_time_of_year_index=cfg.use_time_of_year_index,\n",
    "    cos_zenith_args={\n",
    "            \"dt\": cfg.dt,\n",
    "            \"start_year\": cfg.start_year,\n",
    "        },\n",
    "    batch_size=1,\n",
    "    num_workers=cfg.num_workers,\n",
    "    device=dist.device,\n",
    "    process_rank=dist.rank,\n",
    "    world_size=dist.world_size,\n",
    ")\n",
    "\n",
    "data = next(iter(dp_orig))\n",
    "\n",
    "invar = data[0][\"invar\"]\n",
    "outvar = data[0][\"outvar\"]\n",
    "try:\n",
    "    cos_zenith = data[0][\"cos_zenith\"]\n",
    "except KeyError:\n",
    "    cos_zenith = None\n",
    "try:\n",
    "    time_idx = data[0][\"time_of_year_idx\"].item()\n",
    "except KeyError:\n",
    "    time_idx = None\n",
    "\n",
    "invar_cat = prepare_input(\n",
    "    invar,\n",
    "    cos_zenith,\n",
    "    num_history=cfg.num_history,\n",
    "    static_data=trainer.static_data,\n",
    "    step=1,\n",
    "    time_idx=time_idx,\n",
    "    stride=cfg.stride,\n",
    "    dt=cfg.dt,\n",
    "    num_samples_per_year=cfg.num_samples_per_year_train,\n",
    "    device=dist.device,\n",
    ")\n",
    "invar_cat, outvar = invar_cat.to(dtype=trainer.dtype), outvar.to(dtype=trainer.dtype)\n",
    "\n",
    "print(invar_cat.shape, invar_cat.dtype, outvar.shape, outvar.dtype)\n",
    "\n",
    "\n",
    "trainer.train(invar_cat, outvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nvidia/dali/pipeline.py:912: Warning: The external source node '<modulus.datapipes.climate.era5_hdf5.ERA5DaliExternalSource object at 0xfffba5713e20>' produces 4 outputs, but the outputs at the indices 2, 3 are not used. For best performance, adjust your callback so that it computes only the needed outputs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 721, 1440]) torch.Size([1, 2, 21, 721, 1440])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.3125, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-8:\n",
      "Process SpawnProcess-4:\n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-1:\n",
      "Process SpawnProcess-6:\n",
      "Process SpawnProcess-7:\n",
      "Process SpawnProcess-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 462, in worker\n",
      "    scheduled, shm_chunk = worker_context.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 434, in get_task\n",
      "    scheduled_meta = self.task_receiver.get_task()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/worker.py\", line 132, in get_task\n",
      "    recv = self.queue.get()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 171, in get\n",
      "    waited = self._wait_for_samples()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/nvidia/dali/_multiproc/shared_queue.py\", line 99, in _wait_for_samples\n",
      "    self.cv_not_empty.wait()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 261, in wait\n",
      "    return self._wait_semaphore.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "num_rollout_steps = 2\n",
    "\n",
    "dp_updated = ERA5HDF5Datapipe(\n",
    "    data_dir=os.path.join(cfg.dataset_path, \"train\"),\n",
    "    stats_dir=os.path.join(cfg.dataset_path, \"stats\"),\n",
    "    channels=channels_list,\n",
    "    latlon_resolution=cfg.latlon_res,\n",
    "    interpolation_type=None,\n",
    "    num_samples_per_year=cfg.num_samples_per_year_train,\n",
    "    num_steps=num_rollout_steps,\n",
    "    num_history=cfg.num_history,\n",
    "    use_cos_zenith=cfg.use_cos_zenith,\n",
    "    use_time_of_year_index=cfg.use_time_of_year_index,\n",
    "    cos_zenith_args={\n",
    "        \"dt\": cfg.dt,\n",
    "        \"start_year\": cfg.start_year,\n",
    "    },\n",
    "    batch_size=1,\n",
    "    num_workers=cfg.num_workers,\n",
    "    device=dist.device,\n",
    "    process_rank=dist.rank,\n",
    "    world_size=dist.world_size,\n",
    ")\n",
    "\n",
    "data = next(iter(dp_updated))\n",
    "\n",
    "invar = data[0][\"invar\"]\n",
    "outvar = data[0][\"outvar\"]\n",
    "try:\n",
    "    cos_zenith = data[0][\"cos_zenith\"]\n",
    "except KeyError:\n",
    "    cos_zenith = None\n",
    "try:\n",
    "    time_idx = data[0][\"time_of_year_idx\"].item()\n",
    "except KeyError:\n",
    "    time_idx = None\n",
    "\n",
    "invar_cat = prepare_input(\n",
    "    invar,\n",
    "    cos_zenith,\n",
    "    num_history=cfg.num_history,\n",
    "    static_data=trainer.static_data,\n",
    "    step=1,\n",
    "    time_idx=time_idx,\n",
    "    stride=cfg.stride,\n",
    "    dt=cfg.dt,\n",
    "    num_samples_per_year=cfg.num_samples_per_year_train,\n",
    "    device=dist.device,\n",
    ")\n",
    "invar_cat, outvar = invar_cat.to(dtype=trainer.dtype), outvar.to(dtype=trainer.dtype)\n",
    "\n",
    "print(invar_cat.shape, outvar.shape)\n",
    "\n",
    "trainer.train(invar_cat, outvar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_arm64",
   "language": "python",
   "name": "venv_arm64"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
