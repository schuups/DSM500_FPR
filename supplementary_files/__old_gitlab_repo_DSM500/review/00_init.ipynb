{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127da674-e132-46e7-a492-25509126b7ff",
   "metadata": {},
   "source": [
    "# Modulus GraphCast PT implementation code review\n",
    "\n",
    "[1]Â describes that the model could be trained on a single GPU via `python modulus/examples/weather/graphcast/train_graphcast.py`. This script is external to the module, thus I clone the repo [2] here and include the example script in the path.\n",
    "\n",
    "- [1] https://docs.nvidia.com/deeplearning/modulus/modulus-core/examples/weather/graphcast/readme.html\n",
    "- [2] https://github.com/NVIDIA/modulus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97f1f09-05c0-476b-9d5d-5bdff8d0527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./modulus/examples/weather/graphcast')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8341f30a-830d-4cb0-a77a-0c7c15470b45",
   "metadata": {},
   "source": [
    "---\n",
    "## Configs loading\n",
    "\n",
    "First I load the configs (hydra) as per main annotation. I kept default vals until changes required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d980c1-3e73-4584-9ae9-f289c9939dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'processor_layers': 16, 'hidden_dim': 512, 'mesh_level': 6, 'multimesh': True, 'processor_type': 'MessagePassing', 'khop_neighbors': 32, 'num_attention_heads': 4, 'norm_type': 'TELayerNorm', 'segments': 1, 'force_single_checkpoint': False, 'checkpoint_encoder': True, 'checkpoint_processor': False, 'checkpoint_decoder': False, 'force_single_checkpoint_finetune': False, 'checkpoint_encoder_finetune': True, 'checkpoint_processor_finetune': True, 'checkpoint_decoder_finetune': True, 'concat_trick': True, 'cugraphops_encoder': False, 'cugraphops_processor': False, 'cugraphops_decoder': False, 'recompute_activation': True, 'use_apex': True, 'dataset_path': '/data/era5_75var', 'static_dataset_path': 'static', 'dataset_metadata_path': '/data/era5_75var/metadata/data.json', 'time_diff_std_path': '/time_diff_std.npy', 'latlon_res': [721, 1440], 'num_samples_per_year_train': 1408, 'num_workers': 8, 'num_channels_climate': 73, 'num_channels_static': 5, 'num_channels_val': 3, 'num_val_steps': 8, 'num_val_spy': 3, 'num_history': 0, 'use_cos_zenith': True, 'dt': 6.0, 'start_year': 1980, 'stride': 1, 'use_time_of_year_index': True, 'grad_clip_norm': 32.0, 'jit': False, 'amp': False, 'amp_dtype': 'bfloat16', 'full_bf16': True, 'lr': 0.001, 'lr_step3': 3e-07, 'num_iters_step1': 1000, 'num_iters_step2': 299000, 'num_iters_step3': 11000, 'step_change_freq': 1000, 'save_freq': 1, 'val_freq': 5, 'wb_mode': 'online', 'watch_model': False, 'ckpt_path': 'checkpoints', 'val_dir': 'validation', 'ckpt_name': 'model', 'synthetic_dataset': False, 'pyt_profiler': False, 'profile': False, 'profile_range': '(90, 110)'},\n",
       " 311000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hydra\n",
    "\n",
    "with hydra.initialize(config_path=\"./modulus/examples/weather/graphcast/conf\", version_base=\"1.3\"):\n",
    "    cfg = hydra.compose(config_name=\"config\")\n",
    "cfg, cfg.num_iters_step1 + cfg.num_iters_step2 + cfg.num_iters_step3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7554ef1-a0c6-4bc0-b0ed-2f87529cf493",
   "metadata": {},
   "source": [
    "---\n",
    "## Distributed computation setup\n",
    "\n",
    "Early on [1] on the main() the distributed manager is initialized.\n",
    "\n",
    "- [1] https://vscode.dev/github/NVIDIA/modulus/blob/main/examples/weather/graphcast/train_graphcast.py#L328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a7ac88-48f8-416a-bd03-0396c4a29652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1124 14:58:56.125410238 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modulus.distributed import DistributedManager\n",
    "\n",
    "# I mock a simple slurm job\n",
    "os.environ[\"MODULUS_DISTRIBUTED_INITIALIZATION_METHOD\"] = \"ENV\"\n",
    "os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "\n",
    "DistributedManager.initialize()\n",
    "dist = DistributedManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f3427-2780-46c8-a0db-28e776ef44ca",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataloder initialization\n",
    "\n",
    "Although main() defines its own dataloader on [1] - this is not used until a second phase of training.\n",
    "\n",
    "See [01_dataloader.ipynb](01_dataloader.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8028b-c14f-4094-9d46-9bbb01af4a65",
   "metadata": {},
   "source": [
    "---\n",
    "## Area weights factor computation\n",
    "\n",
    "Right after `datapipe`, `area` is initialized.\n",
    "\n",
    "```python\n",
    "class GraphCastTrainer(BaseTrainer):\n",
    "    def __init__(self, cfg: DictConfig, dist, rank_zero_logger):\n",
    "        ...\n",
    "        self.area = normalized_grid_cell_area(self.lat_lon_grid[:, :, 0], unit=\"deg\")\n",
    "```\n",
    "\n",
    "What is it and what for?\n",
    "\n",
    "See [02_area.ipynb](02_area.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e0a75a-dd3d-45df-92d5-0cfa226eeb34",
   "metadata": {},
   "source": [
    "---\n",
    "## Loss function, optimizer and schedulers\n",
    "\n",
    "After the `area` computation, thus from [1] the loss and optimization objects are initialized. The Adam optimizer and the scheduler are well known, but the loss is a function named `GraphCastLossFunction`.\n",
    "\n",
    "```python\n",
    "class GraphCastTrainer(BaseTrainer):\n",
    "    def __init__(self, cfg: DictConfig, dist, rank_zero_logger):\n",
    "        ...\n",
    "        if cfg.synthetic_dataset:\n",
    "            ...\n",
    "        else:\n",
    "            self.criterion = GraphCastLossFunction(\n",
    "                self.area,\n",
    "                self.channels_list,\n",
    "                cfg.dataset_metadata_path,\n",
    "                cfg.time_diff_std_path,\n",
    "            )\n",
    "```\n",
    "\n",
    "What is it doing?\n",
    "\n",
    "See [03_loss.ipynb](03_loss.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19e1e1",
   "metadata": {},
   "source": [
    "---\n",
    "## Evolution of the training process\n",
    "\n",
    "The training process has different phases. The code is too verbose to make sense, thus a simplified version is proposed in [04_training_process.ipynb](04_training_process.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784695e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model architecture\n",
    "\n",
    "The model architecture analysis is contained in [05_model.ipynb](05_model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae2699",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Icosahedron creation and data structure\n",
    "\n",
    "The icosahedron code is analysed in [06_icosahedron.ipynb](06_icosahedron.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
